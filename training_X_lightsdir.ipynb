{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X39ufJMWhLeP"
   },
   "source": [
    "# Détection de gravure par Deep Learning\n",
    "### But : détecter toutes les gravures sur une image (pas de différences sémantiques)\n",
    "\n",
    "On donne X photos avec des lumières rasantes en entrée au réseau\n",
    "\n",
    "Le dataset est généré dynamiquement par un générateur (les transformations également). Il suffit de donner les relevés et les cartes de normales en paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 136,
     "status": "ok",
     "timestamp": 1750253251651,
     "user": {
      "displayName": "Nino Rottier",
      "userId": "12165733875658235380"
     },
     "user_tz": -120
    },
    "id": "YIEzoMfBORmZ",
    "outputId": "07d15406-50ab-4456-cddd-ee702da40e0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 15 14:38:53 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Quadro RTX 5000                Off |   00000000:73:00.0  On |                  Off |\n",
      "| 33%   33C    P8             24W /  230W |     383MiB /  16384MiB |     39%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3994      G   /usr/lib/xorg/Xorg                             39MiB |\n",
      "|    0   N/A  N/A   1477400      G   /usr/lib/xorg/Xorg                            100MiB |\n",
      "|    0   N/A  N/A   1477529      G   /usr/bin/gnome-shell                           83MiB |\n",
      "|    0   N/A  N/A   1478160      G   /proc/self/exe                                142MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ta76gfjtGKmF"
   },
   "source": [
    "### Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 images in ./dataset/data_nino_limeuil/gravure\n",
      "['56751-36-VERSO.png', '56751-28-VERSO.png', '56751-26-RECTO.png', '56751-28-RECTO.png', '56751-27-VERSO.png', '56751-37-RECTO.png', '56751-25-RECTO.png', '56751-31-RECTO.png', '56751-30-RECTO.png', '56751-35-RECTO.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_to_search = \"./dataset/data_nino_limeuil/gravure\"\n",
    "\n",
    "DATA_NAMES = [f for f in os.listdir(folder_to_search) if f.endswith(\".png\") or f.endswith(\".jpg\") or f.endswith(\".JPG\")]\n",
    "# DATA_NAMES = ['os_0.png', 'os_1.png', 'os_5.png', 'os_2.png', 'os_3.png']\n",
    "print(f\"Found {len(DATA_NAMES)} images in {folder_to_search}\")\n",
    "print(DATA_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1750253273444,
     "user": {
      "displayName": "Nino Rottier",
      "userId": "12165733875658235380"
     },
     "user_tz": -120
    },
    "id": "YGMtKwmaG0AJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of light directions: 8\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCH_SIZE = 40\n",
    "PATCH_SIZE = 512\n",
    "IMG_FOLDER = \"./dataset/data_nino_limeuil/35_light\"\n",
    "GROUNDTRUTH_FOLDER = \"./dataset/data_nino_limeuil/gravure\"\n",
    "PATCH_RATIO = 0.5 # for gravure dilation -> patch selection\n",
    "ROTATION_STEP = 10\n",
    "NOISE_SCALE = 64\n",
    "NOISE_MAX_ANGLE = 5\n",
    "RESCALE = 1.6\n",
    "\n",
    "NB_LIGHTS = 8 # len(os.listdir(os.path.join(IMG_FOLDER, os.listdir(IMG_FOLDER)[0])))  # number of light directions used as input > 1 (otherwise use training_with_datagen.ipynb)\n",
    "print(f\"Number of light directions: {NB_LIGHTS}\") # DOME : 35 // 8 is enough for asserting no coplanarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24312,
     "status": "ok",
     "timestamp": 1750253879090,
     "user": {
      "displayName": "Nino Rottier",
      "userId": "12165733875658235380"
     },
     "user_tz": -120
    },
    "id": "YtwlSXpxNcLR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 14:38:54.838222: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-15 14:38:54.840371: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-15 14:38:54.883482: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-15 14:38:54.884771: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-15 14:38:55.637797: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Loaded image: 56751-36-VERSO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3670, 5496, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Loaded image: 56751-28-VERSO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3670, 5496, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Loaded image: 56751-26-RECTO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3670, 5496, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Loaded image: 56751-28-RECTO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3670, 5496, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Loaded image: 56751-27-VERSO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3648, 4864, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Loaded image: 56751-37-RECTO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3670, 5496, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Loaded image: 56751-25-RECTO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3648, 4864, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Loaded image: 56751-31-RECTO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3670, 5496, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Loaded image: 56751-30-RECTO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3670, 5496, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Loaded image: 56751-35-RECTO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3670, 5496, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Found 2725497 valid patches in 56751-36-VERSO.png\n",
      "* Found 1766276 valid patches in 56751-28-VERSO.png\n",
      "* Found 1753760 valid patches in 56751-26-RECTO.png\n",
      "* Found 2022777 valid patches in 56751-28-RECTO.png\n",
      "* Found 2631208 valid patches in 56751-27-VERSO.png\n",
      "* Found 2055086 valid patches in 56751-37-RECTO.png\n",
      "* Found 600196 valid patches in 56751-25-RECTO.png\n",
      "* Found 1352006 valid patches in 56751-31-RECTO.png\n",
      "* Found 1954215 valid patches in 56751-30-RECTO.png\n",
      "* Found 2715043 valid patches in 56751-35-RECTO.png\n"
     ]
    }
   ],
   "source": [
    "from src.dataGeneratorMultiLights import DataGeneratorMultiLights\n",
    "\n",
    "gen = DataGeneratorMultiLights( # with no normals as input\n",
    "    DATA_NAMES,\n",
    "    BATCH_SIZE,\n",
    "    EPOCH_SIZE,\n",
    "    PATCH_SIZE,\n",
    "    NB_LIGHTS,\n",
    "    IMG_FOLDER,    \n",
    "    GROUNDTRUTH_FOLDER,\n",
    "    PATCH_RATIO,\n",
    "    ROTATION_STEP,\n",
    "    NOISE_SCALE,\n",
    "    NOISE_MAX_ANGLE, # unused if inputs_are_normals=False\n",
    "    RESCALE,\n",
    "    flip=True,\n",
    "    inputs_are_normals=False,\n",
    "    add_padding_needed=True, # otherwise it raises an error\n",
    "    fun_img=lambda x: x / 255.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-KmOKv-yrD4"
   },
   "source": [
    "### Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = PATCH_SIZE\n",
    "IMG_WIDTH = PATCH_SIZE\n",
    "IMG_CHANNELS = 3  # 1 for grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "ok",
     "timestamp": 1750255268573,
     "user": {
      "displayName": "Nino Rottier",
      "userId": "12165733875658235380"
     },
     "user_tz": -120
    },
    "id": "JOu5Lp3aN1C5",
    "outputId": "e486143b-f873-4c49-f26d-af6b1d1628ba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 14:39:55.637037: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 512, 512, 24)]       0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 512, 512, 16)         3472      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 512, 512, 16)         2320      ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 256, 256, 16)         0         ['conv2d_1[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 256, 256, 32)         4640      ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 256, 256, 32)         9248      ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 128, 128, 32)         0         ['conv2d_3[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 128, 128, 64)         18496     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 128, 128, 64)         36928     ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 64, 64, 64)           0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 64, 64, 128)          73856     ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 64, 64, 128)          147584    ['conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 32, 32, 128)          0         ['conv2d_7[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 32, 32, 256)          295168    ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 32, 32, 256)          590080    ['conv2d_8[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 16, 16, 256)          0         ['conv2d_9[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 16, 16, 1024)         2360320   ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 16, 16, 1024)         9438208   ['conv2d_10[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTr  (None, 32, 32, 256)          1048832   ['conv2d_11[0][0]']           \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 32, 32, 512)          0         ['conv2d_transpose[0][0]',    \n",
      "                                                                     'conv2d_9[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 32, 32, 256)          1179904   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 32, 32, 256)          590080    ['conv2d_12[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 64, 64, 128)          131200    ['conv2d_13[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 64, 64, 256)          0         ['conv2d_transpose_1[0][0]',  \n",
      " )                                                                   'conv2d_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 64, 64, 128)          295040    ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 64, 64, 128)          147584    ['conv2d_14[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 128, 128, 64)         32832     ['conv2d_15[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 128, 128, 128)        0         ['conv2d_transpose_2[0][0]',  \n",
      " )                                                                   'conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 128, 128, 64)         73792     ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 128, 128, 64)         36928     ['conv2d_16[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2D  (None, 256, 256, 32)         8224      ['conv2d_17[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 256, 256, 64)         0         ['conv2d_transpose_3[0][0]',  \n",
      " )                                                                   'conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 256, 256, 32)         18464     ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 256, 256, 32)         9248      ['conv2d_18[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2D  (None, 512, 512, 16)         2064      ['conv2d_19[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 512, 512, 32)         0         ['conv2d_transpose_4[0][0]',  \n",
      " )                                                                   'conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 512, 512, 16)         4624      ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 512, 512, 16)         2320      ['conv2d_20[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 512, 512, 1)          17        ['conv2d_21[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16561473 (63.18 MB)\n",
      "Trainable params: 16561473 (63.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#TODO: Essayer d'ajouter une fuzzy layer au début pour gérer les bords de gravure un peu flous\n",
    "#TODO: Ajouter une couche d'attention ?\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import MaxPooling2D, Conv2DTranspose\n",
    "\n",
    "def build_unet_big(input_shape):\n",
    "    # receptive field ~= 800x800 with 6 downsampling layers \n",
    "    # ~ 400x400 with 5\n",
    "\n",
    "    inputs = Input(input_shape)\n",
    "    # Downsampling\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(p1)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(p2)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(p3)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(p4)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c5)\n",
    "    p5 = MaxPooling2D((2, 2))(c5)\n",
    "\n",
    "    # c6 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(p5)\n",
    "    # c6 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c6)\n",
    "    # p6 = MaxPooling2D((2, 2))(c6)\n",
    "\n",
    "    # Bottleneck\n",
    "    b = Conv2D(1024, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(p5)\n",
    "    b = Conv2D(1024, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(b)\n",
    "\n",
    "    # Upsampling\n",
    "    # u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same', kernel_initializer='he_normal')(b)\n",
    "    # u6 = concatenate([u6, c6])\n",
    "    # c7 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(u6)\n",
    "    # c7 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c7)\n",
    "\n",
    "    u5 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same', kernel_initializer='he_normal')(b)\n",
    "    u5 = concatenate([u5, c5])\n",
    "    c8 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(u5)\n",
    "    c8 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c8)\n",
    "\n",
    "    u4 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same', kernel_initializer='he_normal')(c8)\n",
    "    u4 = concatenate([u4, c4])\n",
    "    c9 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(u4)\n",
    "    c9 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c9)\n",
    "\n",
    "    u3 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same', kernel_initializer='he_normal')(c9)\n",
    "    u3 = concatenate([u3, c3])\n",
    "    c10 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(u3)\n",
    "    c10 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c10)\n",
    "\n",
    "    u2 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same', kernel_initializer='he_normal')(c10)\n",
    "    u2 = concatenate([u2, c2])\n",
    "    c11 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(u2)\n",
    "    c11 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c11)\n",
    "\n",
    "    u1 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same', kernel_initializer='he_normal')(c11)\n",
    "    u1 = concatenate([u1, c1])\n",
    "    c12 = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(u1)\n",
    "    c12 = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c12)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid', kernel_initializer='he_normal')(c12)\n",
    "\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "model = build_unet_big((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS*NB_LIGHTS))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Champ réceptif du modèle\n",
    "\n",
    "Utiliser juste pour vérifier le modèle (Attention, cela réinitialise les poids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser uniquement les coefficients (poids) du modèle à 1, laisser les biais inchangés\n",
    "for layer in model.layers:\n",
    "    if hasattr(layer, 'kernel_initializer'):\n",
    "        weights = layer.get_weights()\n",
    "        if weights:\n",
    "            # Généralement, le premier élément est le kernel, le second le biais (si présent)\n",
    "            new_weights = []\n",
    "            for i, w in enumerate(weights):\n",
    "                if i == 0:  # kernel/coefficients\n",
    "                    new_weights.append(np.ones(w.shape, dtype=w.dtype))\n",
    "                else:  # biais ou autres\n",
    "                    new_weights.append(w)\n",
    "            layer.set_weights(new_weights)\n",
    "\n",
    "# Créer une image noire avec un pixel blanc au centre\n",
    "input_img = np.zeros((1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.float32)\n",
    "center_h = IMG_HEIGHT // 2\n",
    "center_w = IMG_WIDTH // 2\n",
    "input_img[0, center_h, center_w, :] = 1.0\n",
    "\n",
    "# Prédiction\n",
    "output = model.predict(input_img)[0, ..., 0]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(output, cmap='hot')\n",
    "plt.title(\"Sortie du modèle (champ réceptif)\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNF51CcodoKb"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses\n",
    "def dice_loss(y_true, y_pred, smooth=1e-8):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    intersection = tf.reduce_sum(y_true*y_pred) #, axis=[1,2,3])\n",
    "    \n",
    "    # union = tf.reduce_sum(y_true + y_pred, axis=[1,2,3])\n",
    "    # dice = (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "    den1 = tf.reduce_sum(y_true * y_true) #, axis=[1, 2, 3])\n",
    "    den2 = tf.reduce_sum(y_pred * y_pred) #, axis=[1, 2, 3])\n",
    "    dice = (2. * intersection + smooth) / (den1 + den2 + smooth)\n",
    "\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    return bce + dice\n",
    "\n",
    "def focal_dice_loss(y_true, y_pred, lambda_bfce=1.0):\n",
    "    bfce = tf.keras.losses.BinaryFocalCrossentropy()(y_true, y_pred)\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    return lambda_bfce * bfce + dice\n",
    "\n",
    "# Metrics\n",
    "def f1_score_metric(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    tp = tf.reduce_sum(y_true * y_pred)\n",
    "    fp = tf.reduce_sum((1 - y_true) * y_pred)\n",
    "    fn = tf.reduce_sum(y_true * (1 - y_pred))\n",
    "    precision = tp / (tp + fp + 1e-6)\n",
    "    recall = tp / (tp + fn + 1e-6)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-6)\n",
    "    return f1\n",
    "\n",
    "# Callbacks\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpoint = ModelCheckpoint(filepath=f'checkpoints/best.weights.h5', save_weights_only=True, save_best_only=True, monitor='loss', mode='min', verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10, mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate Schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "learning_rate_start = 1e-1\n",
    "learning_rate_end = 1e-4\n",
    "\n",
    "lr_schedule_poly = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=learning_rate_start,\n",
    "    decay_steps=500,\n",
    "    end_learning_rate=learning_rate_end,\n",
    "    power=1.0\n",
    ")\n",
    "\n",
    "lr_schedule_exp = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=learning_rate_start,\n",
    "    decay_steps=500,\n",
    "    decay_rate= learning_rate_end / learning_rate_start,\n",
    "    staircase=False\n",
    ")\n",
    "\n",
    "steps_per_epoch = EPOCH_SIZE // BATCH_SIZE\n",
    "lr_schedule_cycle = tfa.optimizers.CyclicalLearningRate(\n",
    "    initial_learning_rate=learning_rate_start,\n",
    "    maximal_learning_rate=learning_rate_end,\n",
    "    step_size=2 * steps_per_epoch,\n",
    "    scale_fn=lambda x: 1 / (2.0 ** (x - 1)),\n",
    "    scale_mode='cycle'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 231499,
     "status": "ok",
     "timestamp": 1750255508586,
     "user": {
      "displayName": "Nino Rottier",
      "userId": "12165733875658235380"
     },
     "user_tz": -120
    },
    "id": "dh3DIWR1N4CC",
    "outputId": "b633c00e-100b-43b8-d867-d23285efbe8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabled check-numerics callback in thread MainThread\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# nan_callback = tf.keras.callbacks.TerminateOnNaN() # essayer ça sinon\u001b[39;00m\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     13\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39madam2,\n\u001b[1;32m     14\u001b[0m     loss\u001b[38;5;241m=\u001b[39mfocal_dice_loss,\n\u001b[1;32m     15\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[f1_score_metric, dice_loss]\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 18\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#callbacks=[checkpoint, early_stopping]\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munet_model_from_normals.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# import gc\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# globals().clear()\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# # kill the kernel to free up memory\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# import os\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# os._exit(0)  # This will terminate the kernel and free up memory\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/detection_gravure/.venv/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/dev/detection_gravure/src/dataGeneratorMultiLights.py:87\u001b[0m, in \u001b[0;36mDataGeneratorMultiLights.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Load all images for this ground truth\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# img_list = self.img_data[rand] # TODO: choisir X (aléatoire parmis celles du dossier) image ici\u001b[39;00m\n\u001b[1;32m     86\u001b[0m img_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 87\u001b[0m sub_imgs_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_name\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m# remove extension of 4 chars (may cause issues if not 4 chars like .png or .jpg)\u001b[39;00m\n\u001b[1;32m     88\u001b[0m rand_imgs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(sub_imgs_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnb_imgs, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_name2 \u001b[38;5;129;01min\u001b[39;00m rand_imgs:\n",
      "File \u001b[0;32m/usr/lib/python3.8/posixpath.py:76\u001b[0m, in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mjoin\u001b[39m(a, \u001b[38;5;241m*\u001b[39mp):\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Join two or more pathname components, inserting '/' as needed.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    If any component is an absolute path, all previous path components\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    will be discarded.  An empty last part will result in a path that\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    ends with a separator.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     sep \u001b[38;5;241m=\u001b[39m _get_sep(a)\n\u001b[1;32m     78\u001b[0m     path \u001b[38;5;241m=\u001b[39m a\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not int"
     ]
    }
   ],
   "source": [
    "# adam = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "# adamW = tf.keras.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "# rmsprop = tf.keras.optimizers.RMSprop(learning_rate=1e-3)\n",
    "# sgd = tf.keras.optimizers.SGD(learning_rate=lr_schedule_cycle)\n",
    "\n",
    "adam2 = tf.keras.optimizers.Adam(learning_rate=1e-3, beta_1=0.5, beta_2=0.5, epsilon=1e-07, amsgrad=False)\n",
    "\n",
    "np.seterr(all='raise') # to check where nan are created\n",
    "tf.debugging.enable_check_numerics() # but it slows the code\n",
    "# nan_callback = tf.keras.callbacks.TerminateOnNaN() # essayer ça sinon\n",
    "\n",
    "model.compile(\n",
    "    optimizer=adam2,\n",
    "    loss=focal_dice_loss,\n",
    "    metrics=[f1_score_metric, dice_loss]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    gen,\n",
    "    epochs=20,\n",
    "    #callbacks=[checkpoint, early_stopping]\n",
    ")\n",
    "\n",
    "model.save('unet_model_from_normals.h5')\n",
    "\n",
    "# import gc\n",
    "# globals().clear()\n",
    "\n",
    "# # kill the kernel to free up memory\n",
    "# import os\n",
    "# os._exit(0)  # This will terminate the kernel and free up memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Courbes & prédictions des batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1750256464603,
     "user": {
      "displayName": "Nino Rottier",
      "userId": "12165733875658235380"
     },
     "user_tz": -120
    },
    "id": "hpJFGK_WQQtS",
    "outputId": "6d3d3777-f88d-4ca4-d07f-28da7617e9bc"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Récupération des données\n",
    "acc = history.history['f1_score_metric']\n",
    "loss = history.history['loss']\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "# Création des graphiques\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Précision\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Train f1-score')\n",
    "plt.title('F1-score over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1-score')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Perte\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Train Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 9409,
     "status": "ok",
     "timestamp": 1750256477050,
     "user": {
      "displayName": "Nino Rottier",
      "userId": "12165733875658235380"
     },
     "user_tz": -120
    },
    "id": "CMhqd0pbN6yK",
    "outputId": "8462bdd8-f4e6-4f00-850e-753307f0c8c4"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Charger le modèle depuis le fichier .h5\n",
    "\n",
    "model = load_model('unet_model_from_normals.h5', custom_objects={'focal_dice_loss': focal_dice_loss, 'f1_score_metric': f1_score_metric, 'dice_loss': dice_loss})\n",
    "\n",
    "# Prédiction sur quelques images du générateur\n",
    "X_batch, y_batch = gen[0]  # Prend un batch\n",
    "# X_batch, y_batch = train_gen[0]  # Prend un batch\n",
    "preds = model.predict(X_batch)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(min(5, X_batch.shape[0])):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow((X_batch[i])) # + 1 )/2)  # Inverse normalization to [0, 1] if inputs are normals\n",
    "    plt.title(\"Normal Map\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(y_batch[i], cmap='gray')\n",
    "    plt.title(\"Ground Truth\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(preds[i, ..., 0], cmap='gray')\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation sur des données réels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser le script [`predict_image.py`](src/predict_image.py) en adaptant bien *fun_img* l.12"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
