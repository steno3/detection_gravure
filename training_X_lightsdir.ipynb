{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X39ufJMWhLeP"
   },
   "source": [
    "# Détection de gravure par Deep Learning\n",
    "### But : détecter toutes les gravures sur une image (pas de différences sémantiques)\n",
    "\n",
    "On donne X photos avec des lumières rasantes en entrée au réseau\n",
    "\n",
    "Le dataset est généré dynamiquement par un générateur (les transformations également). Il suffit de donner les relevés et les cartes de normales en paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 136,
     "status": "ok",
     "timestamp": 1750253251651,
     "user": {
      "displayName": "Nino Rottier",
      "userId": "12165733875658235380"
     },
     "user_tz": -120
    },
    "id": "YIEzoMfBORmZ",
    "outputId": "07d15406-50ab-4456-cddd-ee702da40e0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep 12 17:18:40 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Quadro RTX 5000                Off |   00000000:73:00.0  On |                  Off |\n",
      "| 33%   33C    P5             25W /  230W |    1035MiB /  16384MiB |     15%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3994      G   /usr/lib/xorg/Xorg                             39MiB |\n",
      "|    0   N/A  N/A   1360916      G   /usr/lib/xorg/Xorg                            436MiB |\n",
      "|    0   N/A  N/A   1361045      G   /usr/bin/gnome-shell                          144MiB |\n",
      "|    0   N/A  N/A   1371227      G   /proc/self/exe                                122MiB |\n",
      "|    0   N/A  N/A   1449353      G   /usr/lib/firefox/firefox                      271MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ta76gfjtGKmF"
   },
   "source": [
    "### Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 images in ./dataset/data_nino_limeuil/gravure\n",
      "['56751-36-VERSO.png', '56751-28-VERSO.png', '56751-26-RECTO.png', '56751-28-RECTO.png', '56751-27-VERSO.png', '56751-37-RECTO.png', '56751-25-RECTO.png', '56751-31-RECTO.png', '56751-30-RECTO.png', '56751-35-RECTO.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_to_search = \"./dataset/data_nino_limeuil/gravure\"\n",
    "\n",
    "DATA_NAMES = [f for f in os.listdir(folder_to_search) if f.endswith(\".png\") or f.endswith(\".jpg\") or f.endswith(\".JPG\")]\n",
    "# DATA_NAMES = ['os_0.png', 'os_1.png', 'os_5.png', 'os_2.png', 'os_3.png']\n",
    "print(f\"Found {len(DATA_NAMES)} images in {folder_to_search}\")\n",
    "print(DATA_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1750253273444,
     "user": {
      "displayName": "Nino Rottier",
      "userId": "12165733875658235380"
     },
     "user_tz": -120
    },
    "id": "YGMtKwmaG0AJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of light directions: 35\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCH_SIZE = 40\n",
    "PATCH_SIZE = 512\n",
    "IMG_FOLDER = \"./dataset/data_nino_limeuil/35_light\"\n",
    "GROUNDTRUTH_FOLDER = \"./dataset/data_nino_limeuil/gravure\"\n",
    "PATCH_RATIO = 0.5 # for gravure dilation -> patch selection\n",
    "ROTATION_STEP = 10\n",
    "NOISE_SCALE = 64\n",
    "NOISE_MAX_ANGLE = 5\n",
    "RESCALE = 1.6\n",
    "\n",
    "NB_LIGHTS = len(os.listdir(os.path.join(IMG_FOLDER, os.listdir(IMG_FOLDER)[0])))  # number of light directions used as input > 1 (otherwise use training_with_datagen.ipynb)\n",
    "print(f\"Number of light directions: {NB_LIGHTS}\") # DOME : 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 24312,
     "status": "ok",
     "timestamp": 1750253879090,
     "user": {
      "displayName": "Nino Rottier",
      "userId": "12165733875658235380"
     },
     "user_tz": -120
    },
    "id": "YtwlSXpxNcLR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 17:18:42.865617: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-12 17:18:42.867825: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-12 17:18:42.909551: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-12 17:18:42.911307: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-12 17:18:47.503215: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Loaded image: 56751-36-VERSO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3670, 5496, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Loaded image: 56751-28-VERSO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3670, 5496, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Loaded image: 56751-26-RECTO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3670, 5496, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Loaded image: 56751-28-RECTO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3670, 5496, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Loaded image: 56751-27-VERSO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3648, 4864, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Loaded image: 56751-37-RECTO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3670, 5496, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Loaded image: 56751-25-RECTO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3648, 4864, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Loaded image: 56751-31-RECTO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3670, 5496, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Loaded image: 56751-30-RECTO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3670, 5496, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Loaded image: 56751-35-RECTO.png from ./dataset/data_nino_limeuil/gravure\n",
      "    Image shape: (3670, 5496, 1)\n",
      "    Image min: 0.0, max: 1.0\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5492.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5516.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5490.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5496.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5511.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5522.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5514.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5495.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5507.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5499.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5501.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5515.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5505.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5500.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5506.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5491.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5497.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5512.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5519.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5493.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5520.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5508.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5510.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5517.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5518.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5504.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5502.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5494.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5503.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5509.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5489.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5513.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5521.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5498.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-36-VERSO/_MG_5523.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5958.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5933.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5940.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5946.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5957.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5960.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5963.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5965.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5934.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5935.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5952.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5948.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5939.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5954.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5947.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5949.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5937.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5967.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5942.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5945.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5953.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5964.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5944.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5955.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5951.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5961.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5936.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5959.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5962.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5966.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5938.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5950.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5943.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5941.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-VERSO/_MG_5956.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5772.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5764.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5748.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5750.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5749.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5766.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5780.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5782.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5754.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5752.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5779.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5774.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5763.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5771.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5755.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5770.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5751.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5781.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5759.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5775.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5773.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5758.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5762.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5757.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5767.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5769.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5776.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5777.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5756.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5760.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5765.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5761.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5768.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5753.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-26-RECTO/_MG_5778.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5919.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5906.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5904.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5930.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5920.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5902.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5928.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5901.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5898.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5913.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5927.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5918.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5900.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5925.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5911.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5923.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5915.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5917.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5929.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5926.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5899.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5924.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5897.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5922.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5910.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5912.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5916.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5909.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5896.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5905.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5921.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5903.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5914.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5907.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-28-RECTO/_MG_5908.jpg with size (5472, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0052.JPG with size (4864, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0056.JPG with size (4864, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0045.JPG with size (4864, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0067.JPG with size (4864, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0048.JPG with size (4864, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0057.JPG with size (4864, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0047.JPG with size (4864, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0042.JPG with size (4864, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0060.JPG with size (4864, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0046.JPG with size (4864, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0071.JPG with size (4864, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0073.JPG with size (4864, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0040.JPG with size (4864, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0049.JPG with size (4864, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0044.JPG with size (4864, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0054.JPG with size (4864, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0065.JPG with size (4864, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0062.JPG with size (4864, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0064.JPG with size (4864, 3648)\n",
      "* Loaded image: ./dataset/data_nino_limeuil/35_light/56751-27-VERSO/3D_MAN56751-27_GT89_0061.JPG with size (4864, 3648)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataGeneratorMultiLights\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataGeneratorMultiLights\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# gen = DataGeneratorMultiLights( # with normals as input\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#     DATA_NAMES,\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     BATCH_SIZE,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#     inputs_are_normals=True,\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[43mDataGeneratorMultiLights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# with no normals as input\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDATA_NAMES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mEPOCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mIMG_FOLDER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mGROUNDTRUTH_FOLDER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPATCH_RATIO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mROTATION_STEP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mNOISE_SCALE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mNOISE_MAX_ANGLE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# unused if inputs_are_normals=False\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mRESCALE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_are_normals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_padding_needed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# otherwise it raises an error\u001b[39;49;00m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfun_img\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255.0\u001b[39;49m\n\u001b[1;32m     35\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/detection_gravure/src/dataGeneratorMultiLights.py:51\u001b[0m, in \u001b[0;36mDataGeneratorMultiLights.__init__\u001b[0;34m(self, data_names, batch_size, epoch_size, patch_size, img_folder, groundtruth_folder, patch_ratio, rotation_step, noise_scale, noise_max_angle, rescale, flip, inputs_are_normals, add_padding_needed, fun_img, fun_gt)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Load images and adding padding if needed\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroundtruth_data \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mdataGenerator\u001b[38;5;241m.\u001b[39mDataGenerator\u001b[38;5;241m.\u001b[39mload_data_from_folder(groundtruth_folder, data_names, color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrayscale\u001b[39m\u001b[38;5;124m\"\u001b[39m, fun_traitement\u001b[38;5;241m=\u001b[39mfun_gt)\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_data \u001b[38;5;241m=\u001b[39m \u001b[43mDataGeneratorMultiLights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data_from_multiple_folders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrgb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DataGeneratorMultiLights\u001b[38;5;241m.\u001b[39mare_same_size(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroundtruth_data):\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m add_padding_needed:\n",
      "File \u001b[0;32m~/dev/detection_gravure/src/dataGeneratorMultiLights.py:174\u001b[0m, in \u001b[0;36mDataGeneratorMultiLights.load_data_from_multiple_folders\u001b[0;34m(base_folder, data_names, color_mode)\u001b[0m\n\u001b[1;32m    172\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, img_name)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(img_path):\n\u001b[0;32m--> 174\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m* Loaded image: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    176\u001b[0m     img_array \u001b[38;5;241m=\u001b[39m img_to_array(img)\n",
      "File \u001b[0;32m~/dev/detection_gravure/.venv/lib/python3.8/site-packages/keras/src/utils/image_utils.py:423\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    421\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 423\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath should be path-like or io.BytesIO, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    427\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.dataGeneratorMultiLights import DataGeneratorMultiLights\n",
    "\n",
    "# gen = DataGeneratorMultiLights( # with normals as input\n",
    "#     DATA_NAMES,\n",
    "#     BATCH_SIZE,\n",
    "#     EPOCH_SIZE,\n",
    "#     PATCH_SIZE,\n",
    "#     IMG_FOLDER,\n",
    "#     GROUNDTRUTH_FOLDER, \n",
    "#     PATCH_RATIO, \n",
    "#     ROTATION_STEP, \n",
    "#     NOISE_SCALE,\n",
    "#     NOISE_MAX_ANGLE,\n",
    "#     RESCALE,\n",
    "#     flip=True,\n",
    "#     inputs_are_normals=True,\n",
    "# )\n",
    "\n",
    "gen = DataGeneratorMultiLights( # with no normals as input\n",
    "    DATA_NAMES,\n",
    "    BATCH_SIZE,\n",
    "    EPOCH_SIZE,\n",
    "    PATCH_SIZE,\n",
    "    IMG_FOLDER,\n",
    "    GROUNDTRUTH_FOLDER,\n",
    "    PATCH_RATIO,\n",
    "    ROTATION_STEP,\n",
    "    NOISE_SCALE,\n",
    "    NOISE_MAX_ANGLE, # unused if inputs_are_normals=False\n",
    "    RESCALE,\n",
    "    flip=True,\n",
    "    inputs_are_normals=False,\n",
    "    add_padding_needed=True, # otherwise it raises an error\n",
    "    fun_img=lambda x: x / 255.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-KmOKv-yrD4"
   },
   "source": [
    "### Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = PATCH_SIZE\n",
    "IMG_WIDTH = PATCH_SIZE\n",
    "IMG_CHANNELS = 3  # 1 for grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "ok",
     "timestamp": 1750255268573,
     "user": {
      "displayName": "Nino Rottier",
      "userId": "12165733875658235380"
     },
     "user_tz": -120
    },
    "id": "JOu5Lp3aN1C5",
    "outputId": "e486143b-f873-4c49-f26d-af6b1d1628ba"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#TODO: Essayer d'ajouter une fuzzy layer au début pour gérer les bords de gravure un peu flous\n",
    "#TODO: Ajouter une couche d'attention ?\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import MaxPooling2D, Conv2DTranspose\n",
    "\n",
    "def build_unet(input_shape):\n",
    "    # For 2D RGB input (batch, height, width, channels), use Conv2D, MaxPooling2D, etc.\n",
    "    # receptive field ~= 100x100\n",
    "\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Downsampling\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(p1)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(p2)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    # Bottleneck\n",
    "    b = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(p3)\n",
    "    b = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(b)\n",
    "\n",
    "    # Upsampling\n",
    "    u3 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same', kernel_initializer='he_normal')(b)\n",
    "    u3 = concatenate([u3, c3])\n",
    "    c4 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(u3)\n",
    "    c4 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c4)\n",
    "\n",
    "    u2 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same', kernel_initializer='he_normal')(c4)\n",
    "    u2 = concatenate([u2, c2])\n",
    "    c5 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(u2)\n",
    "    c5 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c5)\n",
    "\n",
    "    u1 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same', kernel_initializer='he_normal')(c5)\n",
    "    u1 = concatenate([u1, c1])\n",
    "    c6 = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(u1)\n",
    "    c6 = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c6)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid', kernel_initializer='he_normal')(c6)\n",
    "\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "def build_unet_big(input_shape):\n",
    "    # receptive field ~= 800x800 with 6 downsampling layers \n",
    "    # ~ 400x400 with 5\n",
    "\n",
    "    inputs = Input(input_shape)\n",
    "    # Downsampling\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(p1)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(p2)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(p3)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(p4)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c5)\n",
    "    p5 = MaxPooling2D((2, 2))(c5)\n",
    "\n",
    "    # c6 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(p5)\n",
    "    # c6 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c6)\n",
    "    # p6 = MaxPooling2D((2, 2))(c6)\n",
    "\n",
    "    # Bottleneck\n",
    "    b = Conv2D(1024, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(p5)\n",
    "    b = Conv2D(1024, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(b)\n",
    "\n",
    "    # Upsampling\n",
    "    # u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same', kernel_initializer='he_normal')(b)\n",
    "    # u6 = concatenate([u6, c6])\n",
    "    # c7 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(u6)\n",
    "    # c7 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c7)\n",
    "\n",
    "    u5 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same', kernel_initializer='he_normal')(b)\n",
    "    u5 = concatenate([u5, c5])\n",
    "    c8 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(u5)\n",
    "    c8 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c8)\n",
    "\n",
    "    u4 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same', kernel_initializer='he_normal')(c8)\n",
    "    u4 = concatenate([u4, c4])\n",
    "    c9 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(u4)\n",
    "    c9 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c9)\n",
    "\n",
    "    u3 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same', kernel_initializer='he_normal')(c9)\n",
    "    u3 = concatenate([u3, c3])\n",
    "    c10 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(u3)\n",
    "    c10 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c10)\n",
    "\n",
    "    u2 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same', kernel_initializer='he_normal')(c10)\n",
    "    u2 = concatenate([u2, c2])\n",
    "    c11 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(u2)\n",
    "    c11 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c11)\n",
    "\n",
    "    u1 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same', kernel_initializer='he_normal')(c11)\n",
    "    u1 = concatenate([u1, c1])\n",
    "    c12 = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(u1)\n",
    "    c12 = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(c12)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid', kernel_initializer='he_normal')(c12)\n",
    "\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "model = build_unet_big((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Champ réceptif du modèle\n",
    "\n",
    "Utiliser juste pour vérifier le modèle (Attention, cela réinitialise les poids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser uniquement les coefficients (poids) du modèle à 1, laisser les biais inchangés\n",
    "for layer in model.layers:\n",
    "    if hasattr(layer, 'kernel_initializer'):\n",
    "        weights = layer.get_weights()\n",
    "        if weights:\n",
    "            # Généralement, le premier élément est le kernel, le second le biais (si présent)\n",
    "            new_weights = []\n",
    "            for i, w in enumerate(weights):\n",
    "                if i == 0:  # kernel/coefficients\n",
    "                    new_weights.append(np.ones(w.shape, dtype=w.dtype))\n",
    "                else:  # biais ou autres\n",
    "                    new_weights.append(w)\n",
    "            layer.set_weights(new_weights)\n",
    "\n",
    "# Créer une image noire avec un pixel blanc au centre\n",
    "input_img = np.zeros((1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.float32)\n",
    "center_h = IMG_HEIGHT // 2\n",
    "center_w = IMG_WIDTH // 2\n",
    "input_img[0, center_h, center_w, :] = 1.0\n",
    "\n",
    "# Prédiction\n",
    "output = model.predict(input_img)[0, ..., 0]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(output, cmap='hot')\n",
    "plt.title(\"Sortie du modèle (champ réceptif)\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNF51CcodoKb"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses\n",
    "def dice_loss(y_true, y_pred, smooth=1e-8):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    intersection = tf.reduce_sum(y_true*y_pred) #, axis=[1,2,3])\n",
    "    \n",
    "    # union = tf.reduce_sum(y_true + y_pred, axis=[1,2,3])\n",
    "    # dice = (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "    den1 = tf.reduce_sum(y_true * y_true) #, axis=[1, 2, 3])\n",
    "    den2 = tf.reduce_sum(y_pred * y_pred) #, axis=[1, 2, 3])\n",
    "    dice = (2. * intersection + smooth) / (den1 + den2 + smooth)\n",
    "\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    return bce + dice\n",
    "\n",
    "def focal_dice_loss(y_true, y_pred, lambda_bfce=1.0):\n",
    "    bfce = tf.keras.losses.BinaryFocalCrossentropy()(y_true, y_pred)\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    return lambda_bfce * bfce + dice\n",
    "\n",
    "# Metrics\n",
    "def f1_score_metric(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    tp = tf.reduce_sum(y_true * y_pred)\n",
    "    fp = tf.reduce_sum((1 - y_true) * y_pred)\n",
    "    fn = tf.reduce_sum(y_true * (1 - y_pred))\n",
    "    precision = tp / (tp + fp + 1e-6)\n",
    "    recall = tp / (tp + fn + 1e-6)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-6)\n",
    "    return f1\n",
    "\n",
    "# Callbacks\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpoint = ModelCheckpoint(filepath=f'checkpoints/best.weights.h5', save_weights_only=True, save_best_only=True, monitor='loss', mode='min', verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10, mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate Schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "learning_rate_start = 1e-1\n",
    "learning_rate_end = 1e-4\n",
    "\n",
    "lr_schedule_poly = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=learning_rate_start,\n",
    "    decay_steps=500,\n",
    "    end_learning_rate=learning_rate_end,\n",
    "    power=1.0\n",
    ")\n",
    "\n",
    "lr_schedule_exp = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=learning_rate_start,\n",
    "    decay_steps=500,\n",
    "    decay_rate= learning_rate_end / learning_rate_start,\n",
    "    staircase=False\n",
    ")\n",
    "\n",
    "steps_per_epoch = EPOCH_SIZE // BATCH_SIZE\n",
    "lr_schedule_cycle = tfa.optimizers.CyclicalLearningRate(\n",
    "    initial_learning_rate=learning_rate_start,\n",
    "    maximal_learning_rate=learning_rate_end,\n",
    "    step_size=2 * steps_per_epoch,\n",
    "    scale_fn=lambda x: 1 / (2.0 ** (x - 1)),\n",
    "    scale_mode='cycle'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 231499,
     "status": "ok",
     "timestamp": 1750255508586,
     "user": {
      "displayName": "Nino Rottier",
      "userId": "12165733875658235380"
     },
     "user_tz": -120
    },
    "id": "dh3DIWR1N4CC",
    "outputId": "b633c00e-100b-43b8-d867-d23285efbe8a"
   },
   "outputs": [],
   "source": [
    "# adam = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "# adamW = tf.keras.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "# rmsprop = tf.keras.optimizers.RMSprop(learning_rate=1e-3)\n",
    "# sgd = tf.keras.optimizers.SGD(learning_rate=lr_schedule_cycle)\n",
    "\n",
    "adam2 = tf.keras.optimizers.Adam(learning_rate=1e-3, beta_1=0.5, beta_2=0.5, epsilon=1e-07, amsgrad=False)\n",
    "\n",
    "np.seterr(all='raise') # to check where nan are created\n",
    "tf.debugging.enable_check_numerics() # but it slows the code\n",
    "# nan_callback = tf.keras.callbacks.TerminateOnNaN() # essayer ça sinon\n",
    "\n",
    "model.compile(\n",
    "    optimizer=adam2,\n",
    "    loss=focal_dice_loss,\n",
    "    metrics=[f1_score_metric, dice_loss]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    gen,\n",
    "    epochs=20,\n",
    "    #callbacks=[checkpoint, early_stopping]\n",
    ")\n",
    "\n",
    "model.save('unet_model_from_normals.h5')\n",
    "\n",
    "# import gc\n",
    "# globals().clear()\n",
    "\n",
    "# # kill the kernel to free up memory\n",
    "# import os\n",
    "# os._exit(0)  # This will terminate the kernel and free up memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Courbes & prédictions des batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1750256464603,
     "user": {
      "displayName": "Nino Rottier",
      "userId": "12165733875658235380"
     },
     "user_tz": -120
    },
    "id": "hpJFGK_WQQtS",
    "outputId": "6d3d3777-f88d-4ca4-d07f-28da7617e9bc"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Récupération des données\n",
    "acc = history.history['f1_score_metric']\n",
    "loss = history.history['loss']\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "# Création des graphiques\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Précision\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Train f1-score')\n",
    "plt.title('F1-score over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1-score')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Perte\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Train Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 9409,
     "status": "ok",
     "timestamp": 1750256477050,
     "user": {
      "displayName": "Nino Rottier",
      "userId": "12165733875658235380"
     },
     "user_tz": -120
    },
    "id": "CMhqd0pbN6yK",
    "outputId": "8462bdd8-f4e6-4f00-850e-753307f0c8c4"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Charger le modèle depuis le fichier .h5\n",
    "\n",
    "model = load_model('unet_model_from_normals.h5', custom_objects={'focal_dice_loss': focal_dice_loss, 'f1_score_metric': f1_score_metric, 'dice_loss': dice_loss})\n",
    "\n",
    "# Prédiction sur quelques images du générateur\n",
    "X_batch, y_batch = gen[0]  # Prend un batch\n",
    "# X_batch, y_batch = train_gen[0]  # Prend un batch\n",
    "preds = model.predict(X_batch)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(min(5, X_batch.shape[0])):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow((X_batch[i])) # + 1 )/2)  # Inverse normalization to [0, 1] if inputs are normals\n",
    "    plt.title(\"Normal Map\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(y_batch[i], cmap='gray')\n",
    "    plt.title(\"Ground Truth\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(preds[i, ..., 0], cmap='gray')\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation sur des données réels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser le script [`predict_image.py`](src/predict_image.py) en adaptant bien *fun_img* l.12"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
